<INTRODUCTION>
Image Captioning in Deep Learning refers to the process whereby computers are trained to automatically generate captions or descriptions for digital images. This falls under the domain of Computer Vision, a subfield of artificial intelligence (AI). The main motivation behind image captioning is to create models capable of understanding images similar to human perception, and producing relevant textual descriptions. Applications range from aiding visually impaired individuals to curating content for social media platforms.

<HISTORY>
The concept of using deep learning techniques for image captioning emerged in the mid-2010s, piggybacking on advancements in both natural language processing (NLP) and computer vision. The work by Vinyals et al. from Google in 2014 played a pivotal role in this field. They introduced a model that combines Convolutional Neural Networks (CNNs) and Long Short-Term Memory (LSTM), tackling the challenge of understanding images and generating coherent, contextually relevant sentences.

<KEY IDEAS>
Key to image captioning is the combined use of CNNs and Recurrent Neural Networks (RNNs), specifically LSTMs. CNNs are used to extract feature vectors from images, enabling the model to 'understand' visual inputs. These vectors are then passed onto LSTMs, capable of understanding temporal sequences, for sentence generation. The goal is to optimize the loss function that measures the difference between generated captions and ground truth captions. The model is capable of learning complex features from raw pixels and making sense out of them, generating sentences based on these learned representations.

<USES/APPLICATIONS>
Image captioning finds wide-ranging applications, from improving web accessibility for visually impaired individuals to aiding content search and discovery on social media platforms. It's also used in surveillance systems where the task is to describe activities in a scene. Additionally, companies are leveraging this technology to provide automatic metadata tagging to facilitate better content management. Other interesting applications include photo editing tools and automatic generation of listing descriptions in e-commerce.

<VARIATIONS>
There are various techniques used in image captioning, such as attention mechanisms, scene-graph-based methods, and Reinforcement Learning-based methods. Some models focus on generating more detailed and comprehensive descriptions, while others tackle the challenge of generating novel sentences or descriptions that are rarely seen in training data. Recent advancements also include Transformers for Image Captioning and Visual Question Answering (VQA) where systems generate answers to questions about the content of images, broadening the scope of how AI can understand and interact with visual data.