<INTRODUCTION>
Residual Neural Network (ResNet) is a deep-learning model proposed by a team of researchers at Microsoft Research that makes use of the residual learning framework to ease the training of networks that are significantly deeper than those used previously. As a part of the convolutional neural network (CNN) family, ResNet is predominantly used in image recognition tasks, delivering unmatched accuracy levels. Its unique architectural innovation - the residual block, helps in resolving the problems associated with training deep neural networks like vanishing and exploding gradients.

<HISTORY>
ResNet was first introduced by Kaiming He and colleagues from Microsoft Research in 2015, in the paper "Deep Residual Learning for Image Recognition." Before ResNet, the prevailing notion was that deeper networks would perform better. However, issues like vanishing and exploding gradients made training deeper networks challenging. To address these challenges and to train much deeper networks, Residual Neural Networks were introduced, pioneering the use of shortcut connections or skip connections that allow layers to learn residual functions.

<KEY IDEAS>
The fundamental idea behind ResNet is to construct layers to learn residual mappings with reference to the layer inputs, rather than learning unreferenced functions. The network adds a shortcut or skip connection that bypasses one or more layers. By doing this, implementations of ResNet allowed the successful training of neural networks with 152 layers, significantly more than previous architectures. This concept is mathematically expressed as F(x) = H(x) - x, where F(x) is the residual mapping to be learnt. This idea reduced the problem of vanishing and exploding gradients, resulting in better model performance.

<USES/APPLICATIONS>
ResNets have emerged as an efficient network architecture in image classification tasks, especially after winning the 1st place in the ImageNet Large-Scale Visual Recognition Challenge (ILSVRC) in 2015. They’re used widely in various domains including autonomous vehicles, airports for facial recognition, healthcare for disease detection through image data, among others. ResNets are also being used for object detection, image segmentation, and even in some Natural Language Processing tasks by incorporating their unique architecture to handle complex data.

<VARIATIONS>
Several variations of the original ResNet model have been introduced over the years, enhancing the efficiency and accuracy of the network. Notable among them are ResNet-D where deformable convolutions are adopted to capture more flexible information, ResNet-v2 that revises the original architecture by pre-activating the weights, and ResNeXt that adds a “cardinality” dimension to improve computational efficiency. Another significant alteration is the DenseNet, where each layer obtains additional inputs from all preceding layers and passes on its own feature-maps to all subsequent layers, creating a dense connectivity pattern. Each model opts for a unique approach to handle training deep networks, contributing to the broader field of deep learning.