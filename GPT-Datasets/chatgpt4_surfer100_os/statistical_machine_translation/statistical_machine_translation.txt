<INTRODUCTION>
Statistical Machine Translation (SMT) is a paradigm in machine translation where statistical methods are used to predict the likelihood of a certain translation given a source phrase. These methods involve training on large corpuses in both the source and target language to learn statistical patterns and associations. SMT is founded on the concept that words and phrases in a text have certain probabilities of being a translation of each other. These probabilities, once learned, can be used to select the most likely translation of a given source text. Despite its complexity, SMT has become a popular field due to the surge in applications related to natural language processing and artificial intelligence.

<HISTORY>
SMT dates back to the early 1990s and was popularized by IBM's Candide project. Initiating research led to the creation of several different SMT models, collectively known as IBM Models 1 to 7, each incrementing in complexity. The initial models operated solely on the word level and disregarded structural differences between languages. Later, the development of the phrase-based SMT model impressed upon the community. A notable evolution occurred when Google deployed SMT for Google Translate, translating sentences instead of individual words. These historical developments have shaped SMT into what it is today, a critical element of machine translation.

<KEY IDEAS>
There are three main components in SMT: the language model, translation model, and the decoder. The language model predicts the likelihood of a sequence of words in the target language appearing together, trained on large corpuses of the target language. The translation model, trained on parallel corpuses of source and target languages, assigns a probability that a source sentence has a certain translation. The decoder uses the probabilities from both models to select the most probable correct translation. One of the key ideas in SMT is that it is data-driven. All the information required for translating is learned from the data itself, not dictated by human experts. 

<VARIATIONS>
SMT models vary by the level at which they translate and the methods they use to align and reorder words and sentences. Phrase-based SMT is the most common approach where translations occur at the phrase level instead of the word level. Other variations include tree-to-tree translation, where parse trees in the source language are used to generate parse trees in the target language, syntax-based SMT, which incorporate elements of syntactic structure into phrase-based models, and more recently, neural SMT, which uses deep learning methods to create a continuous vector space.

<APPLICATIONS>
The most well-known application of SMT is in web-based translation services such as Google Translate. SMT is also used in speech-to-speech translation systems, cross-lingual information retrieval to enable searching documents in different languages, multilingual text summarization, and computer-assisted translation, where the system proposes translations for a human translator to approve or correct. The possibilities for the application of SMT are vast as our digital world grows more connected and multilingual.